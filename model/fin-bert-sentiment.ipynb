{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "./symbol-masked-trainer/checkpoint-50000 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo with `use_auth_token` or log in with `huggingface-cli login` and pass `use_auth_token=True`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\stock-nlp\\lib\\site-packages\\transformers\\configuration_utils.py\u001b[0m in \u001b[0;36m_get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    593\u001b[0m             \u001b[1;31m# Load from URL or cache if already cached\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 594\u001b[1;33m             resolved_config_file = cached_path(\n\u001b[0m\u001b[0;32m    595\u001b[0m                 \u001b[0mconfig_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\stock-nlp\\lib\\site-packages\\transformers\\file_utils.py\u001b[0m in \u001b[0;36mcached_path\u001b[1;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[0;32m   1920\u001b[0m         \u001b[1;31m# URL, so get it from the cache (downloading if necessary)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1921\u001b[1;33m         output_path = get_from_cache(\n\u001b[0m\u001b[0;32m   1922\u001b[0m             \u001b[0murl_or_filename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\stock-nlp\\lib\\site-packages\\transformers\\file_utils.py\u001b[0m in \u001b[0;36mget_from_cache\u001b[1;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[0;32m   2124\u001b[0m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_redirects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2125\u001b[1;33m             \u001b[0m_raise_for_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2126\u001b[0m             \u001b[0metag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"X-Linked-Etag\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ETag\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\stock-nlp\\lib\\site-packages\\transformers\\file_utils.py\u001b[0m in \u001b[0;36m_raise_for_status\u001b[1;34m(request)\u001b[0m\n\u001b[0;32m   2045\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0merror_code\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"RepoNotFound\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2046\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"404 Client Error: Repository Not Found for url: {request.url}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2047\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0merror_code\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"EntryNotFound\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRepositoryNotFoundError\u001b[0m: 404 Client Error: Repository Not Found for url: https://huggingface.co/symbol-masked-trainer/checkpoint-50000/resolve/main/config.json",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8624/1167392516.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"symbol-vocab\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# mask_model = AutoModelForMaskedLM.from_pretrained(\"./symbol-masked-trainer/checkpoint-50000\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./symbol-masked-trainer/checkpoint-50000\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m# model.bert = mask_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\stock-nlp\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"_from_auto\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 424\u001b[1;33m             config, kwargs = AutoConfig.from_pretrained(\n\u001b[0m\u001b[0;32m    425\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_unused_kwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrust_remote_code\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\stock-nlp\\lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    635\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"name_or_path\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m         \u001b[0mtrust_remote_code\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"trust_remote_code\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 637\u001b[1;33m         \u001b[0mconfig_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    638\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m\"auto_map\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"AutoConfig\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"auto_map\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\stock-nlp\\lib\\site-packages\\transformers\\configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[0moriginal_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m         \u001b[1;31m# Get config dict associated with the base config file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 546\u001b[1;33m         \u001b[0mconfig_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_config_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    547\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# That config file may point us toward another config file to use.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\stock-nlp\\lib\\site-packages\\transformers\\configuration_utils.py\u001b[0m in \u001b[0;36m_get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 606\u001b[1;33m             raise EnvironmentError(\n\u001b[0m\u001b[0;32m    607\u001b[0m                 \u001b[1;34mf\"{pretrained_model_name_or_path} is not a local folder and is not a valid model identifier listed on \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    608\u001b[0m                 \u001b[1;34m\"'https://huggingface.co/models'\\nIf this is a private repository, make sure to pass a token having \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: ./symbol-masked-trainer/checkpoint-50000 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo with `use_auth_token` or log in with `huggingface-cli login` and pass `use_auth_token=True`."
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForSequenceClassification, AutoModelForMaskedLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"symbol-vocab\")\n",
    "# mask_model = AutoModelForMaskedLM.from_pretrained(\"./symbol-masked-trainer/checkpoint-50000\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"./symbol-masked-trainer/checkpoint-50000\", num_labels=2)\n",
    "# model.bert = mask_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from glob import glob\n",
    "from datasets import Dataset\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from parse import data_loading\n",
    "\n",
    "data_url = '../crawler/stock/data/**.json'\n",
    "url = glob(data_url)[-1]\n",
    "data = data_loading(url)\n",
    "\n",
    "data['label'].value_counts().plot(kind='bar', title='Count (label)', color=['#1f77b4', '#ff7f0e'])\n",
    "\n",
    "dataset = Dataset.from_pandas(data.loc[:, ['label', 'sentense']])\n",
    "dataset = dataset.remove_columns('__index_level_0__')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(example):\n",
    "    sentense = example['sentense']\n",
    "\n",
    "    result = tokenizer(\n",
    "        sentense,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "    )\n",
    "    return result\n",
    "\n",
    "encoded_dataset = dataset.map(encode, batched=True)\n",
    "encoded_dataset = encoded_dataset.train_test_split(test_size=0.2)\n",
    "# print(encoded_dataset[0]['sentense'])\n",
    "# print(encoded_dataset[0]['input_ids'])\n",
    "# type(encoded_dataset[0]['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import load_metric\n",
    "\n",
    "import numpy as np\n",
    "import wandb\n",
    "\n",
    "%env WANDB_PROJECT=Stocktwit_sentiment_analysis\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"fin-bert-classifier-trainer\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    num_train_epochs=5,\n",
    "    save_steps=5000,\n",
    "    per_device_train_batch_size=4,\n",
    "    report_to=\"wandb\",\n",
    "    run_name=\"fin-bertweet-sentiment-classifier-test-5-epoch\"\n",
    ")\n",
    "\n",
    "recall_metric = load_metric(\"recall\")\n",
    "precision_metric = load_metric(\"precision\")\n",
    "accuracy_metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    recall_result = recall_metric.compute(predictions=predictions, references=labels)\n",
    "    precision_result = precision_metric.compute(predictions=predictions, references=labels)\n",
    "    accuracy_result = accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "    return {**recall_result, **precision_result, **accuracy_result}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_dataset['train'],\n",
    "    eval_dataset=encoded_dataset['test'],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "152c7e0fd5b2c01bebd317ef10822ff01094aee6d45d80a66ab90147e1c50abf"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('stock-nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
